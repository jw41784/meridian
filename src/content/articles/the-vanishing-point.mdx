---
title: "The Vanishing Point"
description: "What if the data that bankrupts strategy is the data you literally can't keep in mind? A deep dive into organizational forgetting, antimemetic knowledge, and the spaces where institutional memory fails to form."
publishDate: 2025-06-01
author: "Jason Williamson"
tags: ["organizational-memory", "knowledge-management", "risk-management", "decision-making"]
---


# The Vanishing Point

*What if the data that bankrupts strategy is the data you literally can't keep in mind?*

## The Space Where Memory Should Be

Mission Control, January 17, 2003. An engineer points at a blur on the screen—foam from the external tank hitting Columbia's wing. They note it. Discuss it. File it.

Sixteen days later, Columbia breaks apart over Texas.

That gap between seeing and disaster haunts me. Not because someone failed to act, but because the memory never quite formed. The foam strike was documented, entered into records. But it never became knowledge that could change decisions or save lives.

This pattern repeats in every boardroom, every risk committee, every strategic review. It's about things that never properly enter organizational memory—knowledge that exists but doesn't quite exist. About how institutions develop ways of unseeing what they've seen.

## The Presence of Absence

Here's a question: How do you know what you've forgotten?

Not the simple stuff—we all forget names, lose track of why we entered a room. I mean something deeper: How does an organization know what it no longer knows?

Paul Ricoeur spent years on this paradox. Memory, he argued, carries what he called "the presence of absence." We don't just forget things—we carry the ghost of what we've forgotten, a void that shapes us as much as what we remember.

You know the feeling. Sometimes you sense you're forgetting something important. You can't name it—if you could, you wouldn't have forgotten it. But your mind detects its own gap. Ricoeur called this the "aporia of memory"—being aware of an absence without being able to fill it.

Now think about an organization with thousands of people, decades of history, terabytes of data. What voids does it carry? What absences shape every meeting, every decision?

The answer: it has no way to know.

Your brain can sometimes detect its own gaps. But organizational memory is scattered across minds, systems, processes. When it forgets, no single part feels the absence. The void is everywhere and nowhere.

This happened with Columbia. NASA didn't forget about foam strikes like you forget a phone number. The information was there—in databases, reports, engineers' minds. But it didn't become institutional memory. It existed in limbo: known but not remembered, documented but not alive.

Or take Wells Fargo, 2016. For years, employees opened unauthorized accounts. Ethics hotlines documented it. Exit interviews mentioned it. Data showed anomalies. But the knowledge wouldn't stick. It contradicted the story too much. Each signal dissolved before forming a pattern.

That absence shaped everything. Every sales meeting that didn't question quotas. Every audit that missed the right questions. Every presentation showing only growth. The missing knowledge bent decisions around itself.

## The Antimemetic Organization

Some knowledge literally can't survive in your organization—and you'll never know what's missing.

In 2008, science fiction writer Sam Hughes imagined "antimemes"—ideas that resist being known, concepts that evade memory by nature. Not hidden secrets, but knowledge that hides itself.

Hughes wrote horror fiction about entities too alien for human minds. But apply this to organizations, and it clicks. Organizations constantly generate knowledge that evaporates on contact with collective consciousness. Not because anyone suppresses it, but because certain information is incompatible with how we've built our systems for knowing.

Think about how organizational memory works. We design it for efficiency, clarity, action. Dashboards with green and red lights. Reports with clear recommendations. Systems that surface signals and filter noise.

But what about knowledge that doesn't fit? The foam strike that's neither green nor red but grey? The pattern visible only across silos, on no single dashboard? The risk that shows up not as a spike but as a drift?

This is antimemetic knowledge—information that organizational systems reject because it's indigestible. Here's why certain knowledge can't stick:

**Stories Over Specifics:** Organizations make sense through stories—beginning, middle, end. But some knowledge won't fit narrative shapes. Those seventy-nine foam strikes before Columbia weren't a story. They were scattered data points, each unique, forming a pattern too subtle for narrative.

**Category Problems:** Mary Douglas showed us that "dirt" is just "matter out of place"—stuff that doesn't fit our categories. Antimemetic knowledge is cognitive dirt. Foam strikes weren't "safety incidents" (no injuries) or "normal operations" (something broke). They lived between categories, impossible to process through normal channels.

**No Clear Owner:** Memory is social. We remember through others, with others. But antimemetic knowledge often lacks ownership. Who owned the foam strike issue? Safety? Engineering? Operations? When knowledge belongs to everyone and no one, it disappears.

**Convenient Forgetting:** Organizations unconsciously forget information that would be costly to remember. For NASA, truly remembering foam strikes meant questioning the Shuttle program's safety. The knowledge wasn't suppressed; it just couldn't overcome institutional inertia.

This isn't rare. It's everywhere. Your organization is swimming in information its architecture can't process. This knowledge exists in your systems right now. But your organization can't see it. Not won't—can't.

## The Recursive Abyss

Organizations don't just forget. They forget that they forget. They lose track of losing track.

I call this recursive forgetting, and it turns simple amnesia into pathology:

**Level 1:** An organization fails to retain knowledge. Foam strikes are noted but don't become memory.

**Level 2:** The organization forgets it once knew this. The concern about foam strikes fades completely.

**Level 3:** The organization forgets it can forget like this. It loses awareness of its memorial limits.

Each level makes the problem worse. At Level 3, organizations exist in memorial unconsciousness—unaware of their unawareness, blind to their blindness.

A consultant told me about a mid-tier bank that survived 2008 through conservative risk management. By 2015, they wanted to understand their "excessive risk aversion." They hired her to investigate.

"I found recursive forgetting. They'd forgotten the close calls that created their risk protocols. Forgotten these were responses to close calls. Forgotten they'd ever been less conservative. Forgotten their conservatism was learned, not inherent."

"They were trying to fix what saved them. But they couldn't see it because they'd forgotten the forgetting."

This is the nightmare: not just amnesia but anosognosia—when patients can't recognize their own deficits. The organization thinks its memory works fine because it doesn't remember it working differently.

How can you learn from mistakes you don't remember making? You can't. And worse—you don't know you can't.

## The Architecture of Absence

Organizational memory is distributed across multiple systems, each with its own way of forgetting:

| Memory Layer | What It Does Well | How It Fails |
|--------------|------------------|--------------|
| Individual Minds | Rich detail | People leave; knowledge stays locked in heads |
| Cultural Patterns | Persists over time | Preserves gist, loses crucial details |
| Social Networks | Spreads information | Knowledge flows through like water through a sieve |
| Physical Spaces | Embodies knowledge | Office moves erase more than we realize |
| Formal Systems | Perfect storage | Can retrieve data but can't judge significance |

The real problem is these systems don't connect. The database doesn't inform the culture. Social networks don't update procedures. Individual knowledge doesn't become collective wisdom.

This creates gaps where knowledge falls and disappears. These gaps aren't empty—they're filled with traces of absent knowledge. The organization acts differently because of what it's forgotten, even though it can't say what.

## What Forgetting Feels Like

What's it like being in an organization that's forgetting something crucial? Usually, nothing. That's the problem—antimemetic knowledge doesn't announce its absence.

But sometimes you can sense it. Employees describe it:

*"Like trying to remember a dream. You know something was important, but it keeps slipping away."*

*"We have the same conversations. Not similar—identical. But nobody notices."*

*"I'll search for something I know we documented, can't find it. Months later it appears, but we've already repeated the mistake."*

You might recognize these feelings:

- That discomfort when everyone agrees too quickly
- The "unexpected" crisis that keeps happening
- The detailed report everyone mentions but hasn't read
- The sense your organization once knew how to handle this

This is life inside an organization with antimemetic knowledge—constant, low-level dissonance, swimming through fog no one admits is there.

## The Cruel Paradox of Documentation

We live in the most documented age ever. Every email archived, every meeting recorded, every decision tracked. Yet organizational forgetting seems to be accelerating. Why?

Information isn't memory. Information is data points. Memory is the connective tissue that gives them meaning. More logs don't mean more insight—they often mean more noise.

When organizations confuse documentation with memory, they create "write-only memory"—archives where information goes but never returns. The foam strike data was meticulously documented. But documentation without use is like a library without readers—preserving knowledge while forgetting it.

These archives create false security. "It's all in the system," we say. But systems don't remember—people do. When we outsource memory to systems, we risk cognitive atrophy.

## The Weight of What We Cannot Hold

There's an ethical dimension we rarely discuss. When organizations forget safety warnings, dismiss risk patterns, or lose their history, they're not just making cognitive errors. They're failing a fundamental responsibility.

Each foam strike, each anomaly, each warning asks to be seen, demands response. When organizations develop ways of not-seeing, they fail not just in knowing but in responding. The forgetting that prevents learning from the past also prevents responsibility for the future.

## In the Space Between

So where does this leave us? If organizations naturally forget, if some knowledge is inherently antimemetic, if forgetting compounds—is there hope?

I don't have easy answers. The problem runs deeper than better databases or knowledge systems. It's built into how groups of humans try to know things together.

But recognizing the phenomenon matters. You can't address what you don't know exists. Most organizations don't know—can't know—they're forgetting, because they've forgotten they can forget.

The NASA engineers who worried about Columbia's foam strike weren't ignored. They were heard, acknowledged. Then the knowledge entered that twilight—present but not present, known but not remembered.

Somewhere in your organization, right now, similar knowledge is forming and failing to form. The presence of absence is shaping decisions in ways no one sees.

We can't eliminate that space between knowing and remembering—the vanishing point where organizational knowledge disappears. But maybe we can learn to see it. Seeing that point keeps the ghosts from steering strategy.

---

*Next: Part 2 - The Gravity Well: How forgetting behaves like gravity—mapping the mass that bends strategic space-time around what organizations can't remember.*

*For insights on navigating organizational complexity beyond conventional wisdom, contact us at [info@eudexio.com](mailto:info@eudexio.com).*